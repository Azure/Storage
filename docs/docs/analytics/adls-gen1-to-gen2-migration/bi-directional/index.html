<!DOCTYPE html>
<html lang="en" dir=>

<head>
  <meta name="generator" content="Hugo 0.82.0" />
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Bi-directional sync pattern Guide: A quick start template #  Overview #  This manual will introduce WANdisco as a recommended tool to set up bi-directional sync between ADLS Gen1 and Gen2 using the Replication feature.
Below will be covered as part of this guide:
 Data Migration from Gen1 to Gen2 Data Consistency Check Application update for ADF, ADB and SQL DWH workloads  Considerations for using the bi-directional sync pattern:">
<meta name="theme-color" content="#FFFFFF"><meta property="og:title" content="Bi-directional sync pattern Guide: A quick start template" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://azurestorage.com/docs/analytics/adls-gen1-to-gen2-migration/bi-directional/" />

<title>Bi-directional sync pattern Guide: A quick start template | Azure Storage</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/book.min.2bc2364a4a4b31f0ec1debecf0a8f90a840821f143dfe1ac6a0f7cbcbdcf64ac.css" integrity="sha256-K8I2SkpLMfDsHevs8Kj5CoQIIfFD3&#43;Gsag98vL3PZKw=">
<script defer src="/en.search.min.431662c1a02a398a5f27e0b5427110bd724c4cfae955414b3a70f1d60c95febe.js" integrity="sha256-QxZiwaAqOYpfJ&#43;C1QnEQvXJMTPrpVUFLOnDx1gyV/r4="></script>
<link rel="alternate" type="application/rss+xml" href="https://azurestorage.com/docs/analytics/adls-gen1-to-gen2-migration/bi-directional/index.xml" title="Azure Storage" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>

<body dir=>
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a href="/"><img src="/images/azure-icon.png" alt="Logo" /><span>Azure Storage</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>











  



  
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://azurestorage.com/docs/analytics/" class="">Analytics</a>
  

          
        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://azurestorage.com/docs/application-and-user-data/" class="">Application and User Data</a>
  

          
        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://azurestorage.com/docs/backup-and-archive/" class="">Backup and Archive</a>
  

          
        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://azurestorage.com/docs/hpc-iot-and-ai/" class="">HPC IoT and AI</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://azurestorage.com/docs/storage-partners/" class="">Storage Partners</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://azurestorage.com/docs/tools-and-utilities/" class="">Tools and Utilities</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://azurestorage.com/docs/whats-new/" class="">What&#39;s New</a>
  

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var a=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(b){localStorage.setItem("menu.scrollTop",a.scrollTop)}),a.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Bi-directional sync pattern Guide: A quick start template</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#overview">Overview</a></li>
    <li><a href="#prerequisites">Prerequisites</a></li>
    <li><a href="#login-to-fusion-ui">Login to Fusion UI</a></li>
    <li><a href="#create-replication-rule">Create Replication Rule</a></li>
    <li><a href="#consistency-check">Consistency Check</a></li>
    <li><a href="#migration-using-livemigrator">Migration using LiveMigrator</a></li>
    <li><a href="#managing-replication">Managing Replication</a></li>
    <li><a href="#application-update">Application Update</a>
      <ul>
        <li><a href="#mount-path-configuration">Mount path configuration</a></li>
        <li><a href="#beginning-state">Beginning State</a></li>
        <li><a href="#interim-state">Interim State</a></li>
        <li><a href="#eventual-end-state">Eventual End State</a></li>
      </ul>
    </li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h1 id="bi-directional-sync-pattern-guide-a-quick-start-template">
  Bi-directional sync pattern Guide: A quick start template
  <a class="anchor" href="#bi-directional-sync-pattern-guide-a-quick-start-template">#</a>
</h1>
<h2 id="overview">
  Overview
  <a class="anchor" href="#overview">#</a>
</h2>
<p>This manual will introduce <a href="https://docs.wandisco.com/bigdata/wdfusion/adls/">WANdisco</a> as a recommended tool to set up bi-directional sync between ADLS Gen1 and Gen2 using the Replication feature.</p>
<p>Below will be covered as part of this guide:</p>
<ul>
<li>Data Migration from Gen1 to Gen2</li>
<li>Data Consistency Check</li>
<li>Application update for ADF, ADB and SQL DWH workloads</li>
</ul>
<p>Considerations for using the bi-directional sync pattern:</p>
<ul>
<li>Ideal for complex scenarios that involve a large number of pipelines and dependencies where a phased approach might make more sense.</li>
<li>Migration effort is high, but it provides side-by-side support for Gen1 and Gen2.</li>
</ul>
<h2 id="prerequisites">
  Prerequisites
  <a class="anchor" href="#prerequisites">#</a>
</h2>
<ul>
<li>
<p><strong>Active Azure Subscription</strong></p>
</li>
<li>
<p><strong>Azure Data Lake Storage Gen1</strong></p>
</li>
<li>
<p><strong>Azure Data Lake Storage Gen2</strong> For more details please refer to :link: <a href="https://docs.microsoft.com/azure/storage/common/storage-account-create">create azure storage account</a></p>
</li>
<li>
<p><strong>Licenses for WANdisco Fusion</strong> that accommodate the volume of data that you want to make available to ADLS Gen2</p>
</li>
<li>
<p><strong>Azure Linux Virtual Machine</strong> Please refer here to know <a href="./wandisco-set-up-and-installation">How to create Azure VM</a></p>
</li>
<li>
<p><strong>Windows SSH client</strong> like <a href="https://www.putty.org/">Putty</a>, <a href="https://gitforwindows.org/">Git for Windows</a>, <a href="https://cygwin.com/">Cygwin</a>, <a href="https://mobaxterm.mobatek.net/">MobaXterm</a></p>
</li>
</ul>
<h2 id="login-to-fusion-ui">
  Login to Fusion UI
  <a class="anchor" href="#login-to-fusion-ui">#</a>
</h2>
<ol>
<li>
<p><strong>Start</strong> the VM in azure portal if not in Running status.</p>
<p><img src="../images/80544309-9b64d400-8965-11ea-9b28-a4e4daf05a3d.png" alt="image" /></p>
</li>
<li>
<p><strong>Start the Fusion</strong></p>
<p>Go to <strong>SSH Client</strong> <a href="./wandisco-set-up-and-installation/#connect-to-vm">Connect</a> and run below commands:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">cd fusion<span style="color:#f92672">-</span>docker<span style="color:#f92672">-</span>compose <span style="color:#75715e">// Change to the repository directory
</span><span style="color:#75715e"></span>
<span style="color:#f92672">./</span>setup<span style="color:#f92672">-</span>env<span style="color:#f92672">.</span>sh <span style="color:#75715e">// set up script
</span><span style="color:#75715e"></span>
docker<span style="color:#f92672">-</span>compose up <span style="color:#f92672">-</span>d <span style="color:#75715e">// start the fusion
</span></code></pre></div></li>
<li>
<p><strong>Login to Fusion UI</strong>. Open the web browser and give the path as below</p>
<p>URL &ndash;&gt; http://{dnsname}:8081</p>
<blockquote>
<p>Note: The DNS name can be taken from VM Overview details.</p>
</blockquote>
</li>
<li>
<p><strong>Set up ADLS Gen1 and Gen2 storage</strong>. <a href="./wandisco-set-up-and-installation/#adls-gen1-and-gen2-configuration">Click here</a> to know more.</p>
</li>
</ol>
<h2 id="create-replication-rule">
  Create Replication Rule
  <a class="anchor" href="#create-replication-rule">#</a>
</h2>
<p>File system content is replicated selectively by defining Replication Rules.These specify the directory in the file system that will be replicated and the Zones that will participate in that replication.</p>
<p>Without any Replication Rules defined, each Zone’s file system operates independently of the others. With the combination of Zones and Replication Rules, WANdisco Fusion gives you complete control over how data is replicated between your file systems and/or object stores.</p>
<p>On the dashboard, create a HCFS rule with the following parameters:</p>
<ul>
<li>
<p>Rule Name = migration (Give any unique name)</p>
</li>
<li>
<p>Path for all storages = /</p>
</li>
<li>
<p>Default exclusions</p>
</li>
<li>
<p>Preserve HCFS Block Size = False</p>
<p><img src="../images/80546359-44153280-896a-11ea-9e12-bb85b6ceeafc.png" alt="image" /></p>
<p>To know more click :link: <a href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/operation/create-rule">how to create rule</a></p>
</li>
</ul>
<p><strong>Click Finish</strong> and wait for the rule to appear on the dashboard.</p>
<h2 id="consistency-check">
  Consistency Check
  <a class="anchor" href="#consistency-check">#</a>
</h2>
<p>Once you have created a <a href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/operation/create-rule">replication rule</a> as per above mentioned steps, run a consistency check to compare the contents between both zones.</p>
<p>On the Rules table, click to View rule.</p>
<ol>
<li>
<p>On the rule page, start consistency check and wait for the Consistency status to update.</p>
<p><img src="../images/80934228-0e15eb00-8d7c-11ea-8a8c-1975e2c0c9ba.png" alt="image" /></p>
</li>
<li>
<p>The Consistency Status will determine the next steps:</p>
<ul>
<li>
<p>Consistent - no action needed</p>
</li>
<li>
<p>Inconsistent - migration required</p>
</li>
</ul>
<p><strong>Consistency check before migration</strong>:</p>
<p><img src="../images/80765875-f418a600-8af8-11ea-9129-0791ccfcba12.png" alt="image" /></p>
<p>To know more refer to <a href="https://docs.wandisco.com/bigdata/wdfusion/2.12/#consistency-check">Consistency Check using WANdisco fusion</a></p>
<blockquote>
<p>Note: <strong>START CONSISTENCY CHECK</strong> is recommended for small set of data volume.</p>
</blockquote>
</li>
</ol>
<h2 id="migration-using-livemigrator">
  Migration using LiveMigrator
  <a class="anchor" href="#migration-using-livemigrator">#</a>
</h2>
<p>Once HCFS replication rule is created, migration activity can be started using the LiveMigrator. This allows migration of data in a single pass while keeping up with all changes to the source storage(ADLS Gen1). As an outcome data consistency is gauranteed between source and target.</p>
<blockquote>
<p>Note: The Gen2 is synchronized with Gen1 source using consistency checks and scheduled migrations.</p>
</blockquote>
<ol>
<li>
<p><strong>Get Sample data</strong></p>
<p>Upload sample data to the ADLS Gen1 storage account, see the <a href="https://docs.microsoft.com/azure/data-lake-store/data-lake-store-get-started-portal#uploaddata">guide</a> to know more.</p>
</li>
<li>
<p>Place it within the home mount point.</p>
</li>
<li>
<p>On the Fusion UI dashboard, view the HCFS rule.</p>
<p><img src="../images/80547216-8c355480-896c-11ea-8adb-1a58d4e1be6c.png" alt="image" /></p>
<p>The overwrite settings needs to be configured. This determines what happens if the LiveMigrator encounters content in the target path with the same name and size.</p>
<ul>
<li>
<p><strong>Skip</strong>: If the filesize is identical between the source and target, the file is skipped. If it’s a different size, the whole file is replaced.</p>
</li>
<li>
<p><strong>Overwrite</strong>: Everything is replaced, even if the file size is identical.</p>
</li>
</ul>
</li>
<li>
<p>Start your migration with the following settings:</p>
<p>Source Zone = adls1</p>
<p>Target Zone = adls2</p>
<p>Overwrite Settings = Skip / Overwrite</p>
</li>
<li>
<p>Wait until the migration is complete, and check the contents in the ADLS Gen2 container.</p>
<p><strong>Consistency check after migration</strong>:</p>
<p><img src="../images/81225979-f8ccd680-8f9e-11ea-9d93-42f8d4ad2c63.png" alt="image" /></p>
<blockquote>
<p>NOTE: A hidden folder :file_folder: .fusion will be present in the ADLS Gen2 path.</p>
</blockquote>
<blockquote>
<p>Limitation: Client based replication is not supported by Fusion UI , so replication process here is manually driven.</p>
</blockquote>
</li>
</ol>
<h2 id="managing-replication">
  Managing Replication
  <a class="anchor" href="#managing-replication">#</a>
</h2>
<p><img src="../images/80843564-7799cc00-8bb9-11ea-89bb-b7009162f6a1.png" alt="image" /></p>
<p>To know more visit <a href="https://docs.wandisco.com/bigdata/wdfusion/2.12/#managing-replication">How to manage replication</a></p>
<h2 id="application-update">
  Application Update
  <a class="anchor" href="#application-update">#</a>
</h2>
<p>As part of this, we will <a href="https://docs.microsoft.com/azure/storage/blobs/data-lake-storage-supported-azure-services">configure services in workloads</a> used and update the applications to point to Gen2 mount after the migration is complete.</p>
<p>We will be covering below azure services</p>
<ul>
<li>Azure Data Factory
<ul>
<li><a href="https://docs.microsoft.com/azure/data-factory/load-azure-data-lake-storage-gen2">Load data into Azure Data Lake Storage Gen2 with Azure Data Factory</a></li>
</ul>
</li>
<li>Azure Databricks
<ul>
<li><a href="https://docs.microsoft.com/azure/databricks/data/data-sources/azure/azure-datalake-gen2">Use with Azure Databricks</a></li>
<li><a href="https://docs.microsoft.com/azure/storage/blobs/data-lake-storage-quickstart-create-databricks-account">Quickstart: Analyze data in Azure Data Lake Storage Gen2 by using Azure Databricks</a></li>
<li><a href="https://docs.microsoft.com/azure/azure-databricks/databricks-extract-load-sql-data-warehouse">Tutorial: Extract, transform, and load data by using Azure Databricks</a></li>
</ul>
</li>
<li>SQL Data Warehouse
<ul>
<li><a href="https://docs.microsoft.com/azure/data-factory/load-azure-sql-data-warehouse">Use with Azure SQL Data Warehouse</a></li>
</ul>
</li>
</ul>
<p>This can be achieved by following a phased approach where in the migration of data, work loads and applications will be validated incrementally.</p>
<h3 id="mount-path-configuration">
  Mount path configuration
  <a class="anchor" href="#mount-path-configuration">#</a>
</h3>
<p>This will show how to set and configure the mount paths for Gen1 and Gen2 in the MountConfiguration script.</p>
<p><strong>Gen1 mount path configuration</strong>:</p>
<p><img src="../images/81219887-4e9c8100-8f95-11ea-8b81-e32122547757.png" alt="image" /></p>
<p><strong>Gen2 mount path configuration</strong>:</p>
<p><img src="../images/81220219-cff41380-8f95-11ea-9295-4df62c7a9afe.png" alt="image" /></p>
<h3 id="beginning-state">
  Beginning State
  <a class="anchor" href="#beginning-state">#</a>
</h3>
<p><strong>Before Migration</strong>&ndash; The data pipeline is on Gen1</p>
<p>In this state the data ingestion from ADB to Raw folder, writing the processed data into the Processed folder and loading the processed data to SQL DW will be happening at Gen1.</p>
<p><img src="../images/81105450-c650aa00-8ec8-11ea-917c-619c6909b2c9.png" alt="image" /></p>
<p>Sample design:</p>
<p><img src="../images/81109171-8a204800-8ece-11ea-9ddc-a8c12007e32a.png" alt="image" /></p>
<p>All the ADB notebooks will be pointing to Gen1 Mount path in this state and the data will be ingested, processed and loaded to SQL DW from Gen1.</p>
<h3 id="interim-state">
  Interim State
  <a class="anchor" href="#interim-state">#</a>
</h3>
<p>In this state we will start with the migration of the existing Gen1 data to Gen2 using <strong>Wandisco fusion</strong>. The data pipeline will be set to Gen1 and Gen2 partially which will include the data ingestion and processing happening at Gen1 meanwhile writing the processed data to SQL DW at Gen2.</p>
<p><img src="../images/81351734-dc519c80-9079-11ea-8a8e-669b65e17b49.png" alt="image" /></p>
<p>Follow the steps for the <a href="#migration-using-livemigrator">migration</a> of Gen1 data to Gen2 for the Raw and Processed data.</p>
<p>Once the data is migrated, run <strong>Consistency check</strong> in Fusion UI. There should be no inconsistencies.</p>
<p><strong>How to change the mount path</strong></p>
<p>This will show how to configure the mount path for the work load Azure Databricks which will load processed data to SQL DW at Gen2.
In the master pipeline in Azure Datafactory, Go to the notebook <strong>settings</strong> &ndash;&gt; <strong>Base parameters</strong> and mount the <strong>RootPathParam</strong> to Gen2.</p>
<p><img src="../images/81126936-b4cfc800-8ef1-11ea-86bc-8550b21a8aa3.png" alt="image" /></p>
<p><strong>Note</strong>: At the end of this state we will acheive to establish data pipeline partially at Gen1 and Gen2.</p>
<h3 id="eventual-end-state">
  Eventual End State
  <a class="anchor" href="#eventual-end-state">#</a>
</h3>
<p><strong>After Migration</strong> &ndash; The data pipeline moved to Gen2</p>
<p>This state depicts when all the work loads and applications are moved from Gen1 to Gen2 and the bi directional replication is ready to   be turned off.</p>
<p><img src="../images/81124187-ad0c2580-8ee9-11ea-9ca5-f1e2327dc2ab.png" alt="image" /></p>
<p>Below are the steps to change the mount path from Gen1 to Gen2 for the Azure Databricks notebook in Azure Datafactory pipeline</p>
<p><img src="../images/81138345-929c7100-8f16-11ea-9e0f-3681d7c76cf1.png" alt="image" /></p>
<p>Run the master pipeline consisting of all the ADB notebooks and check the data. The ingestion and processing of raw data should take place at Gen2 now along with writing to SQL DW.
This can be verified by checking the data at Gen2 storage. And when <strong>Consistency check</strong> is run using WAndisco Fusion UI , there will be files missing at Gen1.</p>
<p><img src="../images/81352652-ed9ba880-907b-11ea-9cf2-c1620b28455a.png" alt="image" /></p>
<blockquote>
<p>Note: This marks the state where all the workloads are moved to Gen2. Gen1 will not revieve any new data in any form.</p>
</blockquote>
<p><strong>Cutover from Gen1 to Gen2</strong>
After all the applications and workloads are stable on Gen2, Turn off any remaining pipelines that are running on Gen1 and decommission your Gen1 account. This will include deletion of the rules created for the migration and replication process. Shutting down the Azure VM and deleting the resource group.</p>
<h2 id="references">
  References
  <a class="anchor" href="#references">#</a>
</h2>
<ul>
<li><a href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/preparation/azure_vm_creation">WANdisco fusion Installation and set up guide</a></li>
<li><a href="https://www.wandisco.com/products/live-migrator">WANdisco LiveMigrator</a></li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>

 
        <hr />
Azure Storage &copy;2021 <br />
Visit the <a href="https://azure.microsoft.com/services/storage/">Azure Storage homepage</a> or read our <a href="https://docs.microsoft.com/azure/storage/">getting started guide</a> or the <a href="https://azure.microsoft.com/blog/topics/storage-backup-and-recovery/">Azure Storage Blog</a>. <br />
Contact us: <a href="mailto:azurestoragefeedback@microsoft.com?subject=AzureStorage.com%20Feedback">azurestoragefeedback@microsoft.com</a>.<br />
Generated on Mon, Mar 22 2021 14:37:40 UTC
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#overview">Overview</a></li>
    <li><a href="#prerequisites">Prerequisites</a></li>
    <li><a href="#login-to-fusion-ui">Login to Fusion UI</a></li>
    <li><a href="#create-replication-rule">Create Replication Rule</a></li>
    <li><a href="#consistency-check">Consistency Check</a></li>
    <li><a href="#migration-using-livemigrator">Migration using LiveMigrator</a></li>
    <li><a href="#managing-replication">Managing Replication</a></li>
    <li><a href="#application-update">Application Update</a>
      <ul>
        <li><a href="#mount-path-configuration">Mount path configuration</a></li>
        <li><a href="#beginning-state">Beginning State</a></li>
        <li><a href="#interim-state">Interim State</a></li>
        <li><a href="#eventual-end-state">Eventual End State</a></li>
      </ul>
    </li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin="anonymous"></script>

<script>
    $('a[href^="http://"], a[href^="https://"]').not('a[href*="'+location.hostname+'"]').attr('target','_blank');
</script>

<script type="text/javascript">
    !function(T,l,y){var S=T.location,u="script",k="instrumentationKey",D="ingestionendpoint",C="disableExceptionTracking",E="ai.device.",I="toLowerCase",b="crossOrigin",w="POST",e="appInsightsSDK",t=y.name||"appInsights";(y.name||T[e])&&(T[e]=t);var n=T[t]||function(d){var g=!1,f=!1,m={initialize:!0,queue:[],sv:"4",version:2,config:d};function v(e,t){var n={},a="Browser";return n[E+"id"]=a[I](),n[E+"type"]=a,n["ai.operation.name"]=S&&S.pathname||"_unknown_",n["ai.internal.sdkVersion"]="javascript:snippet_"+(m.sv||m.version),{time:function(){var e=new Date;function t(e){var t=""+e;return 1===t.length&&(t="0"+t),t}return e.getUTCFullYear()+"-"+t(1+e.getUTCMonth())+"-"+t(e.getUTCDate())+"T"+t(e.getUTCHours())+":"+t(e.getUTCMinutes())+":"+t(e.getUTCSeconds())+"."+((e.getUTCMilliseconds()/1e3).toFixed(3)+"").slice(2,5)+"Z"}(),iKey:e,name:"Microsoft.ApplicationInsights."+e.replace(/-/g,"")+"."+t,sampleRate:100,tags:n,data:{baseData:{ver:2}}}}var h=d.url||y.src;if(h){function a(e){var t,n,a,i,r,o,s,c,p,l,u;g=!0,m.queue=[],f||(f=!0,t=h,s=function(){var e={},t=d.connectionString;if(t)for(var n=t.split(";"),a=0;a<n.length;a++){var i=n[a].split("=");2===i.length&&(e[i[0][I]()]=i[1])}if(!e[D]){var r=e.endpointsuffix,o=r?e.location:null;e[D]="https://"+(o?o+".":"")+"dc."+(r||"services.visualstudio.com")}return e}(),c=s[k]||d[k]||"",p=s[D],l=p?p+"/v2/track":config.endpointUrl,(u=[]).push((n="SDK LOAD Failure: Failed to load Application Insights SDK script (See stack for details)",a=t,i=l,(o=(r=v(c,"Exception")).data).baseType="ExceptionData",o.baseData.exceptions=[{typeName:"SDKLoadFailed",message:n.replace(/\./g,"-"),hasFullStack:!1,stack:n+"\nSnippet failed to load ["+a+"] -- Telemetry is disabled\nHelp Link: https://go.microsoft.com/fwlink/?linkid=2128109\nHost: "+(S&&S.pathname||"_unknown_")+"\nEndpoint: "+i,parsedStack:[]}],r)),u.push(function(e,t,n,a){var i=v(c,"Message"),r=i.data;r.baseType="MessageData";var o=r.baseData;return o.message='AI (Internal): 99 message:"'+("SDK LOAD Failure: Failed to load Application Insights SDK script (See stack for details) ("+n+")").replace(/\"/g,"")+'"',o.properties={endpoint:a},i}(0,0,t,l)),function(e,t){if(JSON){var n=T.fetch;if(n&&!y.useXhr)n(t,{method:w,body:JSON.stringify(e),mode:"cors"});else if(XMLHttpRequest){var a=new XMLHttpRequest;a.open(w,t),a.setRequestHeader("Content-type","application/json"),a.send(JSON.stringify(e))}}}(u,l))}function i(e,t){f||setTimeout(function(){!t&&m.core||a()},500)}var e=function(){var n=l.createElement(u);n.src=h;var e=y[b];return!e&&""!==e||"undefined"==n[b]||(n[b]=e),n.onload=i,n.onerror=a,n.onreadystatechange=function(e,t){"loaded"!==n.readyState&&"complete"!==n.readyState||i(0,t)},n}();y.ld<0?l.getElementsByTagName("head")[0].appendChild(e):setTimeout(function(){l.getElementsByTagName(u)[0].parentNode.appendChild(e)},y.ld||0)}try{m.cookie=l.cookie}catch(p){}function t(e){for(;e.length;)!function(t){m[t]=function(){var e=arguments;g||m.queue.push(function(){m[t].apply(m,e)})}}(e.pop())}var n="track",r="TrackPage",o="TrackEvent";t([n+"Event",n+"PageView",n+"Exception",n+"Trace",n+"DependencyData",n+"Metric",n+"PageViewPerformance","start"+r,"stop"+r,"start"+o,"stop"+o,"addTelemetryInitializer","setAuthenticatedUserContext","clearAuthenticatedUserContext","flush"]),m.SeverityLevel={Verbose:0,Information:1,Warning:2,Error:3,Critical:4};var s=(d.extensionConfig||{}).ApplicationInsightsAnalytics||{};if(!0!==d[C]&&!0!==s[C]){method="onerror",t(["_"+method]);var c=T[method];T[method]=function(e,t,n,a,i){var r=c&&c(e,t,n,a,i);return!0!==r&&m["_"+method]({message:e,url:t,lineNumber:n,columnNumber:a,error:i}),r},d.autoExceptionInstrumented=!0}return m}(y.cfg);(T[t]=n).queue&&0===n.queue.length&&n.trackPageView({})}(window,document,{
    src: "https://az416426.vo.msecnd.net/scripts/b/ai.2.min.js", 
    
    
    
    
    cfg: { 
        instrumentationKey: "0600b273-5440-42cc-9fe4-51924c721ce0"
         
    }});
</script>
</body>

</html>












